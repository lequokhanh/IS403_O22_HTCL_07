{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv('../../../.Dataset/BTC-USD-3.2018-3.2024.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the date as the index\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.set_index('Date')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def createFeatures(df):\n",
    "    df = pd.DataFrame(df)\n",
    "\n",
    "    \n",
    "    # df['Close_Diff'] = df['Adj Close'].diff()\n",
    "        \n",
    "    # Moving averages - different periods\n",
    "    df['MA200'] = df['Close'].rolling(window=200).mean() \n",
    "    df['MA100'] = df['Close'].rolling(window=100).mean() \n",
    "    df['MA50'] = df['Close'].rolling(window=50).mean() \n",
    "    df['MA26'] = df['Close'].rolling(window=26).mean() \n",
    "    df['MA20'] = df['Close'].rolling(window=20).mean() \n",
    "    df['MA12'] = df['Close'].rolling(window=12).mean() \n",
    "    \n",
    "    # SMA Differences - different periods\n",
    "    df['DIFF-MA200-MA50'] = df['MA200'] - df['MA50']\n",
    "    df['DIFF-MA200-MA100'] = df['MA200'] - df['MA100']\n",
    "    df['DIFF-MA200-CLOSE'] = df['MA200'] - df['Close']\n",
    "    df['DIFF-MA100-CLOSE'] = df['MA100'] - df['Close']\n",
    "    df['DIFF-MA50-CLOSE'] = df['MA50'] - df['Close']\n",
    "    \n",
    "    # Moving Averages on high, lows, and std - different periods\n",
    "    # df['MA200_low'] = df['Low'].rolling(window=200).min()\n",
    "    # df['MA14_low'] = df['Low'].rolling(window=14).min()\n",
    "    # df['MA200_high'] = df['High'].rolling(window=200).max()\n",
    "    # df['MA14_high'] = df['High'].rolling(window=14).max()\n",
    "    df['MA20dSTD'] = df['Close'].rolling(window=20).std() \n",
    "    \n",
    "    # Exponential Moving Averages (EMAS) - different periods\n",
    "    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA20'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
    "    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['EMA100'] = df['Close'].ewm(span=100, adjust=False).mean()\n",
    "    df['EMA200'] = df['Close'].ewm(span=200, adjust=False).mean()\n",
    "\n",
    "    # Shifts (one day before and two days before)\n",
    "    df['close_shift-1'] = df.shift(-1)['Close']\n",
    "    df['close_shift-2'] = df.shift(-2)['Close']\n",
    "\n",
    "    # Bollinger Bands\n",
    "    df['Bollinger_Upper'] = df['MA20'] + (df['MA20dSTD'] * 2)\n",
    "    df['Bollinger_Lower'] = df['MA20'] - (df['MA20dSTD'] * 2)\n",
    "    df['Bollinger_Middle'] = df['MA20'] \n",
    "    \n",
    "    # Relative Strength Index (RSI)\n",
    "    # df['K-ratio'] = 100*((df['Close'] - df['MA14_low']) / (df['MA14_high'] - df['MA14_low']) )\n",
    "    # Relative Strength Index (RSI) not using the K-ratio\n",
    "    # df['RSI'] = df['K-ratio'].rolling(window=3).mean() \n",
    "\n",
    "    # Moving Average Convergence/Divergence (MACD)\n",
    "    df['MACD'] = df['EMA12'] - df['EMA26']\n",
    "    \n",
    "    # Replace nas \n",
    "    nareplace = df.at[df.index.max(), 'Close']    \n",
    "    df.fillna((nareplace), inplace=True)\n",
    "    \n",
    "    # \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of considered Features\n",
    "FEATURES = [\n",
    "            # 'High',\n",
    "            # 'Low',\n",
    "            # 'Open',\n",
    "            'Close',\n",
    "            # 'Volume',\n",
    "#             'Day',\n",
    "#             'Month',\n",
    "#             'Year',\n",
    "            # 'Adj Close',\n",
    "#              'close_shift-1',\n",
    "#              'close_shift-2',\n",
    "            'MACD',\n",
    "            # 'RSI',\n",
    "            # 'MA200',\n",
    "#             'MA200_high',\n",
    "#             'MA200_low',\n",
    "            'Bollinger_Upper',\n",
    "            'Bollinger_Lower',\n",
    "            # 'MA100',            \n",
    "#             'MA50',\n",
    "            'MA26',\n",
    "#             'MA14_low',\n",
    "#             'MA14_high',\n",
    "            # 'MA12',\n",
    "            'EMA20',\n",
    "            # 'EMA100',\n",
    "#             'EMA200',\n",
    "#               'DIFF-MA200-MA50',\n",
    "#               'DIFF-MA200-MA100',\n",
    "#             'DIFF-MA200-CLOSE',\n",
    "#             'DIFF-MA100-CLOSE',\n",
    "#             'DIFF-MA50-CLOSE',\n",
    "            # 'MA20dSTD',\n",
    "            # 'Close_Diff',\n",
    "            # 'K-ratio'\n",
    "           ]\n",
    "\n",
    "# Create the dataset with features\n",
    "df_features = createFeatures(data)\n",
    "\n",
    "# Shift the timeframe by 10 month -> Start date is 2010-11-01\n",
    "use_start_date = pd.to_datetime(\"2018-10-01\")\n",
    "df_features = df_features[df_features.index > use_start_date].copy()\n",
    "\n",
    "# Filter the data to the list of FEATURES\n",
    "df_filtered = df_features[FEATURES].copy()\n",
    "\n",
    "# Filter the data to the list of FEATURES\n",
    "print(df_filtered.head().to_string())  \n",
    "    \n",
    "\n",
    "# Filter the data to the list of FEATURES\n",
    "df_filtered = df_filtered.dropna()\n",
    "print(df_filtered.head().to_string())\n",
    "\n",
    "# Create the lineplot\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(df_filtered)\n",
    "plt.title('BTC/USD Close price')\n",
    "plt.grid()\n",
    "plt.legend(df_filtered.columns)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "df = df_filtered.copy()\n",
    "\n",
    "# Transform the data by scaling each feature to a range between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "np_data = scaler.fit_transform(df)\n",
    "\n",
    "# Creating a separate scaler that works on a single column for scaling predictions\n",
    "scaler_pred = MinMaxScaler()\n",
    "df_close = pd.DataFrame(df['Close'])\n",
    "np_close = scaler_pred.fit_transform(df_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the sequence length - this is the timeframe used to make a single prediction\n",
    "sequence_length = 7\n",
    "\n",
    "# Training, validation, test\n",
    "train_size = int(len(np_data) * 0.70)\n",
    "test_size = len(np_data) - train_size\n",
    "train_data, test_data = np_data[0:train_size], np_data[train_size:len(np_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The RNN needs data with the format of [samples, time steps, features]\n",
    "# Here, we create N samples, sequence_length time steps per sample, and 6 features\n",
    "def partition_dataset(data, time_steps):\n",
    "    x, y = [], []\n",
    "    data_len = data.shape[0]\n",
    "    for i in range(data_len - time_steps):\n",
    "        row = [r for r in data[i: i + time_steps]]\n",
    "        x.append(row)\n",
    "        label = data[i + time_steps][0]\n",
    "        y.append(label)\n",
    "    return np.array(x), np.array(y)\n",
    "    \n",
    "\n",
    "# Generate training data and test data\n",
    "X_train, y_train = partition_dataset(train_data, sequence_length)\n",
    "X_test, y_test = partition_dataset(test_data, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes: the result is: (rows, training_sequence, features) (prediction value, )\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "x_train = X_train.reshape(X_train.shape[0], X_train.shape[1], len(FEATURES))\n",
    "x_test = X_test.reshape(X_test.shape[0], X_test.shape[1], len(FEATURES))\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Configure the Neural Network Model with n Neurons - inputshape = t Timestamps x f Features\n",
    "n_neurons = X_train.shape[1] * x_train.shape[2]\n",
    "print('timesteps: ' + str(x_train.shape[1]) + ',' + ' features:' + str(x_train.shape[2]))\n",
    "# model.add(GRU(n_neurons, input_shape=(x_train.shape[1], x_train.shape[2]))) \n",
    "# model.add(Dense(1))\n",
    "model.add(SimpleRNN(n_neurons, return_sequences=True,\n",
    "          input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(SimpleRNN(n_neurons, return_sequences=True))\n",
    "model.add(SimpleRNN(n_neurons))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "# Configure the Model   \n",
    "optimizer='adam'; loss='mean_squared_error'; epochs = 100; batch_size = 64\n",
    "\n",
    "# uncomment to customize the learning rate\n",
    "learn_rate = \"standard\" # 0.05\n",
    "\n",
    "parameter_list = ['epochs ' + str(epochs), 'batch_size ' + str(batch_size), 'optimizer ' + str(optimizer) + ' with learn rate ' + str(learn_rate), 'loss ' + str(loss)]\n",
    "print('Parameters: ' + str(parameter_list))\n",
    "\n",
    "# Compile and Training the model\n",
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "# Plot training & validation loss values\n",
    "fig, ax = plt.subplots(figsize=(12, 6), sharex=True)\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"Model loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get x_val, x_test for the prediction from the last sequence_length days of the training set and the first sequence_length days of the validation set\n",
    "x_test_pred = np.concatenate((x_train[-sequence_length:], x_test))\n",
    "print(x_test_pred.shape)\n",
    "# Predict the values\n",
    "y_test_pred = model.predict(x_test_pred)\n",
    "\n",
    "# Inverse the scaling of the predicted values\n",
    "y_test_pred_unscaled = scaler_pred.inverse_transform(y_test_pred)\n",
    "\n",
    "\n",
    "# Create a dataframe for the test set matching sliding window\n",
    "day_test = pd.to_datetime(df_filtered.index[-len(y_test_pred):])\n",
    "df_test = pd.DataFrame(day_test, columns=['Date'])\n",
    "df_test['Y_test_pred'] = y_test_pred_unscaled\n",
    "df_test['Y_test'] = df_filtered['Close'][-len(y_test_pred):].values\n",
    "df_test.set_index('Date', inplace=True)\n",
    "\n",
    "\n",
    "# # Plot df_val and df_test\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(df_test['Y_test_pred'], label='Y_test_pred')\n",
    "plt.plot(df_test['Y_test'], label='Y_test')\n",
    "plt.title('BTC/USD Close price')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame(np_data, columns=FEATURES)\n",
    "# Loop to predict the next day\n",
    "i = 1\n",
    "num_days = 90\n",
    "while i <= num_days:\n",
    "    # Get the last sequence_length days\n",
    "    x_pred = df_temp[-sequence_length:]\n",
    "    x_pred_input = x_pred.values\n",
    "    x_pred_input = x_pred_input.reshape(1, sequence_length, len(FEATURES))\n",
    "    print(\"x_pred_input of day \" + str(i) + \": \\n\" + str(x_pred_input))\n",
    "    # Predict the value\n",
    "    y_pred = model.predict(x_pred_input)\n",
    "    y_pred_unscaled = scaler_pred.inverse_transform(y_pred)\n",
    "    print(\"y_pred of day \" + str(i) + \": \" + str(y_pred_unscaled))\n",
    "    # unscaling the data df_temp\n",
    "    df_temp = pd.DataFrame(scaler.inverse_transform(df_temp), columns=FEATURES)\n",
    "    # Add the predicted value to the df_temp dataframe\n",
    "    df_temp = pd.concat([df_temp, pd.DataFrame(y_pred_unscaled, columns=['Close'])], ignore_index=True)\n",
    "    # Create features for the predicted value\n",
    "    df_temp = createFeatures(df_temp)\n",
    "    df_temp = df_temp[FEATURES].copy()\n",
    "    df_temp = df_temp.dropna()\n",
    "    # Scale the data\n",
    "    df_temp = pd.DataFrame(scaler.fit_transform(df_temp), columns=FEATURES)\n",
    "\n",
    "    # Increment the counter\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast_unscale = pd.DataFrame(scaler.inverse_transform(df_temp), columns=FEATURES)\n",
    "df_forecast_unscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the df_temp with the predicted values\n",
    "df_forecast = df_temp[-num_days:]\n",
    "\n",
    "# Unscale the data\n",
    "df_forecast_unscale = pd.DataFrame(scaler.inverse_transform(df_forecast), columns=FEATURES)\n",
    "\n",
    "# Create dataframe forecast with the predicted values and the dates\n",
    "day_forecast = pd.to_datetime(df_filtered.index[-1] + pd.DateOffset(1))\n",
    "df_forecast_unscale['Date'] = pd.date_range(start=day_forecast, periods=num_days, freq='D')\n",
    "df_forecast_unscale.set_index('Date', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dateframe of Close training set\n",
    "df_train = df_filtered['Close'][:train_size].copy()\n",
    "\n",
    "# Plot the forecast for df_val, df_test and df_forecast\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(df_train, label='Train')\n",
    "plt.plot(df_test['Y_test_pred'], label='Test prediction')\n",
    "plt.plot(df_test['Y_test'], label='Test')\n",
    "plt.plot(df_forecast_unscale['Close'], label='Forecast next 30 days')\n",
    "plt.title('BTC/USD Close price')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    smape = np.mean((np.abs(y_pred - y_true) * 200 / (np.abs(y_pred) + np.abs(y_true))))\n",
    "    return rmse, mape, smape\n",
    "\n",
    "# Calculate the metrics df_test\n",
    "rmse, mape, smape = calculate_metrics(df_test['Y_test'], df_test['Y_test_pred'])\n",
    "print('Metrics for Test Data:')\n",
    "print('RMSE: ', rmse)\n",
    "print('MAPE: ', mape)\n",
    "print('SMAPE: ', smape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
